# Tier 5: Specialized & Backend Passes
**Status**: üìã Planned | **Passes**: 28 | **Estimated Effort**: 6‚Äì12 weeks | **Target**: Week 23-34

---

## Overview

Tier 5 contains specialized passes for specific ecosystems (Emscripten, JS interop), feature lowering (convert advanced WebAssembly features to MVP), and niche optimizations. These are **lower priority** for achieving core functional parity but essential for ecosystem integration.

**Key Characteristic**: Most passes are independent and can be implemented in parallel. Priority should be driven by actual user demand.

---

## Group 5A: Emscripten Integration

**Passes**: 4 | **Effort**: 8-12 days

### Pass List
1. **post-emscripten** ‚Äî Emscripten-specific cleanup
2. **optimize-for-js** ‚Äî JavaScript interop optimization
3. **legalize-js-interface** / **legalize-and-prune-js-interface** ‚Äî Validate JS interface
4. **generate-dyncalls** / **generate-i64-dyncalls** ‚Äî Generate dynamic call helpers

### Purpose

These passes clean up and optimize code generated by Emscripten's compiler toolchain. They handle specific patterns that Emscripten emits and make them more efficient.

**post-emscripten** (3-4 days):
- Remove unnecessary Emscripten glue code
- Optimize memory initialization patterns
- Clean up indirect calls

**optimize-for-js** (2-3 days):
- Optimize operations for JS execution (e.g., prefer i32 over i64 where possible)
- Handle JS number limitations

**legalize-js-interface** (2-3 days):
- Ensure import/export types are JS-compatible
- Convert i64 parameters to i32 pairs if needed

**C++ References**:
- `src/passes/PostEmscripten.cpp` (~600 lines)
- `src/passes/OptimizeForJS.cpp` (~400 lines)
- `src/passes/LegalizeJSInterface.cpp` (~500 lines)

---

## Group 5B: Feature Lowering

**Passes**: 8 | **Effort**: 24-40 days

### Pass List
1. **translate-to-exnref** / **strip-eh** ‚Äî Exception handling translation
2. **i64-to-i32-lowering** ‚Äî Lower 64-bit to 32-bit
3. **memory64-lowering** / **table64-lowering** ‚Äî Lower 64-bit memory addresses
4. **multi-memory-lowering** / **multi-memory-lowering-with-bounds-checks** ‚Äî Simplify multi-memory
5. **llvm-nontrapping-fptoint-lowering** ‚Äî FP conversion lowering
6. **llvm-memory-copy-fill-lowering** ‚Äî Lower bulk memory operations
7. **signext-lowering** (also in Tier 2C) ‚Äî Lower sign extensions

### Purpose

Convert advanced WebAssembly features to MVP (Minimum Viable Product) features for compatibility with older runtimes or different targets.

**i64-to-i32-lowering** (5-7 days):
- Replace i64 operations with pairs of i32 operations
- Handle all i64 arithmetic, comparisons, loads, stores
- Used for JS environments without BigInt support

**Example**:
```wasm
;; Before:
(i64.add (local.get $x) (local.get $y))

;; After (conceptual):
;; Split into high/low 32-bit components
(call $i64_add_impl 
  (local.get $x_low) (local.get $x_high)
  (local.get $y_low) (local.get $y_high)
)
```

**memory64-lowering** (4-5 days):
- Convert 64-bit memory indices to 32-bit
- Add bounds checks if needed
- Handle address wrapping

**C++ References**:
- `src/passes/I64ToI32Lowering.cpp` (~800 lines)
- `src/passes/Memory64Lowering.cpp` (~600 lines)
- `src/passes/TranslateToExnref.cpp` (~400 lines)

---

## Group 5C: Specialized Optimization

**Passes**: 8 | **Effort**: 24-40 days

### Pass List
1. **asyncify** ‚Äî Transform for async/await (‚ö†Ô∏è complex, 1000+ lines)
2. **spill-pointers** ‚Äî Spill pointer values to stack (for Boehm GC)
3. **souperify** / **souperify-single-use** ‚Äî Generate Souper IR for super-optimization
4. **safe-heap** ‚Äî Add heap overflow checks
5. **stack-check** ‚Äî Add stack overflow checks
6. **instrument-memory** / **instrument-locals** ‚Äî Instrumentation for debugging
7. **heap2local** ‚Äî Convert heap accesses to locals (when safe)
8. **optimize-j2cl** / **merge-j2cl-itables** ‚Äî Java-to-Closure optimizations

### Pass: asyncify (10-15 days, highly complex)

**Purpose**: Enable async/await style programming in synchronous WebAssembly by adding stack saving/restoring

**Algorithm** (simplified):
1. Identify functions that may pause (contain async calls)
2. Instrument function entry/exit to save/restore stack state
3. Add global "asyncify state" variable
4. Transform control flow to support unwinding/rewinding

**Why Complex**:
- Must handle arbitrary call graphs
- Requires stack state management
- Control flow transformation is intricate
- Many edge cases (exception handling, indirect calls, etc.)

**C++ Reference**: `src/passes/Asyncify.cpp` (~1200 lines)

**Note**: This is one of the most complex passes. Consider lower priority unless specifically needed.

---

### Pass: heap2local (5-7 days)

**Purpose**: Replace GC allocations with local variables when safe (escape analysis)

**Algorithm**:
1. Identify struct allocations that don't escape function
2. Replace with local variables (one per field)
3. Replace struct.get/struct.set with local.get/local.set
4. Remove allocation

**Example**:
```wasm
;; Before:
(local $obj (ref $Point))
(local.set $obj (struct.new $Point (i32.const 1) (i32.const 2)))
(struct.get $Point 0 (local.get $obj))  ;; Access x field

;; After:
(local $point_x i32)
(local $point_y i32)
(local.set $point_x (i32.const 1))
(local.set $point_y (i32.const 2))
(local.get $point_x)  ;; Direct access, no allocation
```

**C++ Reference**: `src/passes/Heap2Local.cpp` (~600 lines)

---

## Group 5D: String & Advanced Features

**Passes**: 5 | **Effort**: 10-20 days

### Pass List
1. **string-gathering** / **string-lifting** / **string-lowering** ‚Äî String operations
2. **fpcast-emu** ‚Äî Emulate function pointer casts
3. **generate-dyncalls** (also in 5A) ‚Äî Generate dynamic call tables
4. **tuple-optimization** ‚Äî Optimize tuple operations

### Purpose

Handle specialized WebAssembly features like strings (proposal), function pointer casting, and multi-value (tuple) operations.

**string-lowering** (3-4 days):
- Lower high-level string operations to byte arrays + imports
- Handle string imports/exports

**fpcast-emu** (2-3 days):
- Emulate function pointer casts for incorrect indirect calls
- Add trampolines to adapt signatures

**tuple-optimization** (2-3 days):
- Eliminate trivial tuples
- Optimize multi-value return patterns

**C++ References**:
- `src/passes/StringLowering.cpp` (~400 lines)
- `src/passes/FuncCastEmulation.cpp` (~500 lines)
- `src/passes/TupleOptimization.cpp` (~300 lines)

---

## Group 5E: Debugging & Analysis

**Passes**: 3 | **Effort**: 6-12 days

### Pass List
1. **dwarfdump** ‚Äî Dump DWARF debug info
2. **trace-calls** ‚Äî Trace function calls
3. **log-execution** ‚Äî Log execution events

### Purpose

Diagnostic and debugging utilities. Not optimizations, but useful for development and debugging.

**dwarfdump** (3-4 days):
- Parse DWARF sections from binary
- Pretty-print debug information
- Useful for debugging compiler output

**trace-calls** / **log-execution** (1-2 days each):
- Instrument code to print execution flow
- Add calls to imported logging functions
- Useful for debugging and profiling

**C++ References**:
- `src/passes/DWARFDump.cpp` (~300 lines)
- `src/passes/TraceCalls.cpp` (~200 lines)
- `src/passes/LogExecution.cpp` (~250 lines)

---

## Tier 5 Implementation Strategy

### Prioritization by Demand

Unlike Tiers 1-4, Tier 5 passes should be prioritized based on **actual user needs**, not implementation order:

**High Priority (implement first)**:
1. **post-emscripten** ‚Äî If targeting Emscripten ecosystem
2. **i64-to-i32-lowering** ‚Äî If JS interop without BigInt needed
3. **legalize-js-interface** ‚Äî For JS compatibility
4. **asyncify** ‚Äî If async/await support needed (complex, defer if possible)

**Medium Priority**:
5. Exception handling lowering (if using exceptions)
6. Memory64 lowering (if targeting 32-bit environments)
7. Instrumentation passes (for debugging)

**Low Priority** (defer unless specifically requested):
8. Souper integration
9. J2CL optimizations (only if using Closure compiler)
10. String operations (only if using string proposal)

---

## Timeline (Flexible)

**Week 23-24**: Emscripten integration (if needed)
- post-emscripten
- optimize-for-js
- legalize-js-interface

**Week 25-27**: Critical feature lowering
- i64-to-i32-lowering
- memory64-lowering
- Exception handling

**Week 28-30**: Specialized opts (as needed)
- heap2local
- Select passes from 5C based on demand

**Week 31-32**: Remaining feature lowering
- Multi-memory lowering
- LLVM-specific lowering

**Week 33-34**: Debugging & polish
- Instrumentation passes
- DWARF support
- Final testing

---

## Success Criteria

### Quantitative
- ‚úÖ All 28 Tier 5 passes implemented (76 ‚Üí 104+ total)
- ‚úÖ Functional parity: ~95-100% of C++ capability
- ‚úÖ Ecosystem integration: Emscripten, JS interop complete

### Qualitative
- ‚úÖ Full feature lowering capability
- ‚úÖ Production-ready for all major use cases
- ‚úÖ Debugging infrastructure in place

### Ecosystem Readiness
- ‚úÖ Can optimize Emscripten output
- ‚úÖ JS interop works correctly
- ‚úÖ Feature lowering handles all WebAssembly proposals

---

## Remaining Passes (Not in Tiers 1-5)

After completing Tiers 1-5, there are still ~18 "test-only" or highly specialized passes:

**Test/Internal Passes**:
- catch-pop-fixup
- deinstrument-branch-hints
- delete-branch-hints
- experimental-type-generalizing
- randomize-branch-hints
- reorder-globals-always
- reorder-types-for-testing

**Specialized/Rare**:
- dealign (force alignment=1 for testing)
- separate-data-segments (split data from code)
- limit-segments (web loader limits)
- set-globals (testing utility)
- enclose-world (destructive, testing)
- extract-function / extract-function-index (debugging)
- roundtrip (write binary, read back)
- once-reduction (niche optimization)

**Implementation Strategy**: Only implement if specifically needed. Most are testing utilities or extremely niche.

---

## Final State After All Tiers

### Complete Pass Inventory

| Tier | Passes | Status | Parity |
|------|--------|--------|--------|
| Current | 6 | ‚úÖ Done | 5% |
| Tier 1 | 19 | üìã Planned | 20% |
| Tier 2 | 24 | üìã Planned | 40% |
| Tier 3 | 18 | üìã Planned | 55% |
| Tier 4 | 28 | üìã Planned | 75% |
| Tier 5 | 28 | üìã Planned | 95% |
| Remaining | ~18 | ‚ö†Ô∏è Deferred | 100% |
| **Total** | **122+** | | |

### Timeline Summary

| Phase | Duration | Cumulative | Parity |
|-------|----------|------------|--------|
| Foundation (Current) | ‚Äî | Done | 5% |
| Tier 1 | 2-3 weeks | Week 1-2 | 20% |
| Tier 2 | 3-4 weeks | Week 3-5 | 40% |
| Tier 3 | 3-5 weeks | Week 6-9 | 55% |
| Tier 4 | 4-8 weeks | Week 10-16 | 75% |
| Tier 5 | 6-12 weeks | Week 17-30 | 95% |
| **Total** | **~30 weeks** | **7-8 months** | **95%+** |

**Key Milestone**: **50% parity (Tier 1-2) in 5 weeks**  
**Production Ready**: **75% parity (Tiers 1-4) in 16 weeks (~4 months)**  
**Full Parity**: **95% parity in 30 weeks (~7 months)**

---

## Conclusion

The 117-pass gap is **tractable** when organized by implementation affinity. The tier system provides:

1. **Clear milestones**: Each tier delivers measurable value
2. **Parallelizable work**: Teams can work on different groups simultaneously
3. **Incremental delivery**: Users get optimization benefits early (after Tier 3)
4. **Risk management**: High-impact passes prioritized, niche passes deferred
5. **Realistic timeline**: 7-8 months to 95% parity (vs. years of random porting)

**Recommendation**: 
- **Immediate**: Complete Tier 1 (quick wins, foundational infrastructure)
- **Short-term**: Tiers 2-3 (single-function optimization, OptimizeInstructions)
- **Medium-term**: Tier 4 (inlining, whole-module analysis)
- **Long-term**: Tier 5 (ecosystem integration, as needed)

This strategy transforms an overwhelming 117-pass backlog into a **manageable, well-structured project** with clear progress markers and deliverable value at each stage.
